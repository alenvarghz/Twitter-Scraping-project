{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b6327fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "st.header(':blue[_TWEETY_]')\n",
    "st.subheader(':blue[_lets scrape some data_]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.image(\"twitterrr.jpg\")\n",
    "\n",
    "with st.form(key='twitter_form'):\n",
    "    search_term = st.text_input('What do you want to search for?')\n",
    "    limit = st.slider('How many tweets do you want to get?', 0, 1000, step=20)\n",
    "   \n",
    "    file_name = st.text_input('Name the CSV file:')\n",
    "   \n",
    "    start_date=st.date_input(\"starting date\",datetime.date(2000,1,1))\n",
    "    end_date=st.date_input(\"ending date\",datetime.date(2020,1,1))\n",
    "    submit_button = st.form_submit_button(label='display')\n",
    "    \n",
    "    if submit_button:\n",
    "        \n",
    "        query = f\"(from:{search_term}) until:{end_date} since:{start_date}\"\n",
    "        tweets = []\n",
    "        limit = limit\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            if len(tweets) == limit:\n",
    "                break\n",
    "            else:\n",
    "                tweets.append([tweet.date, tweet.user, tweet.content, tweet.url, tweet.id, tweet.replyCount, tweet.retweetCount,\n",
    "                       tweet.source, tweet.likeCount])\n",
    "        df = pd.DataFrame(tweets,\n",
    "                  columns=['Date', 'User', 'Tweet', 'Url', 'Id', 'Replycount', 'Retweetcount', 'Source', 'Likecount'])\n",
    "        \n",
    "        df.to_csv(f'{file_name}.csv')\n",
    "        data=pd.read_csv(f'{file_name}.csv')\n",
    "        st.dataframe(data)\n",
    "        \n",
    "\n",
    "try:\n",
    "    def convert_df(df):\n",
    "        return df.to_csv().encode()\n",
    "    st.download_button(label=\"Download data as CSV\",data=convert_df(data) ,file_name='tweets.csv',mime='text/csv')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    st.button(\"Upload to Database\")\n",
    "    if st.button:\n",
    "        import pymongo\n",
    "        client = pymongo.MongoClient(\"mongodb+srv://alen:1234@cluster0.yrmsenw.mongodb.net/?retryWrites=true&w=majority\")\n",
    "        db = client.test1\n",
    "        x=db.twitter\n",
    "        \n",
    "        import pandas as pd\n",
    "        df=pd.read_csv(f\"{file_name}.csv\")\n",
    "        dataa=df.to_dict('records')\n",
    "        x.insert_many(dataa)\n",
    "        \n",
    "        \n",
    "except :\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
